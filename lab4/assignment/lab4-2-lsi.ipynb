{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *X*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Linqi LIU*\n",
    "* *Yifei SONG*\n",
    "* *Ying Xu Dempster TAY*\n",
    "* *Yuhang YAN*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "courses = []\n",
    "with open('data/courses.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        courses.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the TF-IDF matrix\n",
    "tfidf_matrix = np.load('TFIDF_matrix.npy')\n",
    "\n",
    "# Load document and term indices\n",
    "document_indices = np.load('document_indices.npy', allow_pickle=True)\n",
    "terms_indices = np.load('terms_indices.npy', allow_pickle=True)\n",
    "\n",
    "# document_indices = document_indices.tolist() if isinstance(document_indices, np.ndarray) else document_indices\n",
    "# terms_indices = terms_indices.tolist() if isinstance(terms_indices, np.ndarray) else terms_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (5262, 854)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U matrix shape: (5262, 300)\n",
      "S matrix shape: (300,)\n",
      "Vt matrix shape: (300, 854)\n"
     ]
    }
   ],
   "source": [
    "K = 300\n",
    "\n",
    "U, S, Vt = svds(tfidf_matrix, k=K)\n",
    "\n",
    "print(\"U matrix shape:\", U.shape)\n",
    "print(\"S matrix shape:\", S.shape)\n",
    "print(\"Vt matrix shape:\", Vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "1. U Matrix  \n",
    "Shape: (5262, 300)  \n",
    "Rows: Each row corresponds to a term, represented by its \"strength of membership\" to each of the 300 latent factors.  \n",
    "Columns: Each column corresponds to a latent factor, represented by the \"strengths of membership\" of each of the 5262 terms.  \n",
    "2. Vt Matrix  \n",
    "Shape: (300, 854)  \n",
    "Rows: Each row corresponds to a latent factor, represented by its relevance to each of the 854 courses.  \n",
    "Columns: Each column corresponds to a course, represented by the relevances of each of the 300 latent factors.  \n",
    "3. S Matrix  \n",
    "Shape: (300,) (since S is a diagonal matrix, it can be represented as a one-dimensional array)  \n",
    "Values: The S matrix contains singular values, which are sorted in descending order of magnitude, representing the importance of the latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 singular values:\n",
      " 1: 3.5298219675119173\n",
      " 2: 3.1064315388392276\n",
      " 3: 2.072652694410268\n",
      " 4: 1.8660719395787877\n",
      " 5: 1.3928356151088297\n",
      " 6: 1.3457022159036005\n",
      " 7: 1.2734044343384363\n",
      " 8: 1.2339605990753981\n",
      " 9: 1.213415203613278\n",
      "10: 1.174911340154373\n",
      "11: 1.1696397934536829\n",
      "12: 1.1672398683810892\n",
      "13: 1.1580087026072818\n",
      "14: 1.1292889056712745\n",
      "15: 1.1137563771145385\n",
      "16: 1.0927817325774516\n",
      "17: 1.0875044048298685\n",
      "18: 1.0785561640648744\n",
      "19: 1.0552986431911284\n",
      "20: 1.0403463282550436\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 singular values:\")\n",
    "sorted_singular_values = S[::-1]\n",
    "\n",
    "for i, singular_value in enumerate(sorted_singular_values[:20], start=1):\n",
    "    print(f\"{i:>2}: {singular_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the top 10 topics\n",
    "top_k_topics = 10\n",
    "\n",
    "# Get the top 10 terms for each topic\n",
    "terms_per_topic = 10\n",
    "top_terms_indices = np.argsort(-np.abs(U), axis=0)[:terms_per_topic]\n",
    "\n",
    "# Get the top 10 documents for each topic\n",
    "docs_per_topic = 10\n",
    "top_docs_indices = np.argsort(-np.abs(Vt), axis=1)[:, :docs_per_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 topics:\n",
      "Topic 1 (Singular Value: 3.5298):\n",
      "  Top terms: ['markov', 'biophys', 'turbul', 'hilbert', 'evolut', 'sustain', 'wing', 'pollut', 'genom', 'lipid']\n",
      "  Top documents: ['CH-415', 'ENV-200', 'ME-467', 'MICRO-515', 'EE-432', 'EE-543', 'MSE-656', 'MSE-464', 'MATH-635', 'FIN-612']\n",
      "\n",
      "Topic 2 (Singular Value: 3.1064):\n",
      "  Top terms: ['frequenc', 'inequ', 'stabil', 'HF', 'sustain', 'fpga', 'real', 'engin', 'section', 'deriv']\n",
      "  Top documents: ['CH-704', 'MATH-407', 'EE-603', 'EE-470', 'CS-473', 'CH-444', 'CIVIL-444', 'BIOENG-404', 'MATH-463', 'MSE-657']\n",
      "\n",
      "Topic 3 (Singular Value: 2.0727):\n",
      "  Top terms: ['wood', 'biophys', 'volatil', 'data', 'speci', 'rate', 'privaci', 'hpc', 'composit', 'sustain']\n",
      "  Top documents: ['MSE-466', 'CH-415', 'MICRO-607', 'FIN-503', 'FIN-505', 'ENG-802', 'BIO-657', 'PHYS-301', 'ME-608', 'CH-311']\n",
      "\n",
      "Topic 4 (Singular Value: 1.8661):\n",
      "  Top terms: ['beam', 'IP', 'privaci', 'secur', 'learn', 'tribolog', 'planet', 'planetari', 'set', 'stress']\n",
      "  Top documents: ['ME-231(a)', 'MATH-360', 'EE-586', 'BIO-657', 'MGT-404', 'ME-231(b)', 'COM-506', 'CS-712', 'EE-719', 'MSE-619']\n",
      "\n",
      "Topic 5 (Singular Value: 1.3928):\n",
      "  Top terms: ['philosoph', 'negoti', 'inequ', 'grid', 'hpc', 'genom', 'roleplay', 'sound', 'gene', 'wood']\n",
      "  Top documents: ['MGT-466', 'HUM-429(b)', 'MATH-407', 'MSE-600', 'EE-548', 'MATH-474', 'MSE-202', 'MICRO-709', 'MSE-621', 'ENG-627']\n",
      "\n",
      "Topic 6 (Singular Value: 1.3457):\n",
      "  Top terms: ['user', 'IP', 'month', 'HF', 'industri', 'convert', 'wood', 'nanomateri', 'grid', 'planetari']\n",
      "  Top documents: ['BIO-699(m)', 'CS-486', 'MGT-404', 'EE-586', 'EE-533', 'BIO-657', 'EE-432', 'CS-712', 'ChE-603', 'ME-453']\n",
      "\n",
      "Topic 7 (Singular Value: 1.2734):\n",
      "  Top terms: ['negoti', 'spatial', 'simul', 'inequ', 'roleplay', 'volatil', 'reinforc', 'grid', 'epitaxi', 'stereoselect']\n",
      "  Top documents: ['MGT-466', 'MATH-311', 'MATH-407', 'COM-712', 'CIVIL-522', 'MSE-624', 'HUM-422(a)', 'CH-709', 'PHYS-738', 'EE-714']\n",
      "\n",
      "Topic 8 (Singular Value: 1.2340):\n",
      "  Top terms: ['hpc', 'reinforc', 'swiss', 'market', 'section', 'dna', 'beam', 'month', 'datacent', 'credit']\n",
      "  Top documents: ['CIVIL-522', 'CS-712', 'HUM-422(a)', 'BIO-699(m)', 'MATH-454', 'FIN-504', 'MSE-600', 'PHYS-719', 'ME-231(a)', 'CH-415']\n",
      "\n",
      "Topic 9 (Singular Value: 1.2134):\n",
      "  Top terms: ['volatil', 'stereoselect', 'wood', 'photochem', 'IP', 'metabol', 'colloid', 'turbomachin', 'multiantenna', 'negoti']\n",
      "  Top documents: ['FIN-503', 'CH-709', 'EE-543', 'BIO-657', 'MSE-464', 'CS-712', 'CH-442', 'CH-630(2)', 'CH-630(1)', 'ME-453']\n",
      "\n",
      "Topic 10 (Singular Value: 1.1749):\n",
      "  Top terms: ['composit', 'lti', 'rate', 'incom', 'realiz', 'partit', 'epitaxi', 'fix', 'wireless', 'ccd']\n",
      "  Top documents: ['FIN-505', 'MSE-440', 'CH-444', 'EE-205', 'CH-242(a)', 'ENG-609', 'CIVIL-522', 'HUM-422(a)', 'ME-618', 'MGT-404']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top 10 topics as a combination of 10 terms and 10 documents along with the singular values\n",
    "print(\"Top 10 topics:\")\n",
    "for topic_idx in range(top_k_topics):\n",
    "    singular_value = S[::-1][topic_idx]  # S is sorted in ascending order, so we reverse it\n",
    "    print(f\"Topic {topic_idx + 1} (Singular Value: {singular_value:.4f}):\")\n",
    "    print(\"  Top terms:\", [terms_indices[i] for i in top_terms_indices[:, topic_idx]])\n",
    "    print(\"  Top documents:\", [document_indices[i] for i in top_docs_indices[topic_idx, :]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label:  \n",
    "Topic 1: Evolution - Theoretical and evolutionary concepts.   \n",
    "Topic 2: Engineering - Engineering principles and computational methods.   \n",
    "Topic 3: Data - Data analysis and biophysics.  \n",
    "Topic 4: Security - Privacy and security in mechanical systems.  \n",
    "Topic 5: Philosophy - Philosophical and computational science.  \n",
    "Topic 6: Industry - Industrial applications and materials.  \n",
    "Topic 7: Simulation - Negotiation and simulation techniques.  \n",
    "Topic 8: Market - Market analysis and high-performance computing.  \n",
    "Topic 9: Chemistry - Advanced chemistry and photochemistry.  \n",
    "Topic 10: Wireless - Composite materials and wireless communication.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document similarity search function using LSI concept-space\n",
    "def sim_score(term_idx, doc_idx):\n",
    "    U_t = U[term_idx]\n",
    "    V_d = Vt[:, doc_idx]  # Note that Vt is the transpose of V in SVD\n",
    "    sv = S * V_d\n",
    "    return np.dot(U_t, sv) / (norm(U_t) * norm(sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert courses to a dictionary for quick lookup by courseId\n",
    "course_dict = {course['courseId']: course for course in courses}\n",
    "\n",
    "# Convert term_ids to a dictionary\n",
    "term_dict = {term: idx for idx, term in enumerate(terms_indices)}\n",
    "\n",
    "# Get the index of the terms \"markov\" and \"facebook\"\n",
    "markov_idx = term_dict[\"markov\"]\n",
    "facebook_idx = term_dict[\"facebook\"]\n",
    "\n",
    "# Compute the similarity of \"markov chains\" with every course\n",
    "sim_markov = [sim_score(markov_idx, i) for i in range(Vt.shape[1])]\n",
    "\n",
    "# Compute the similarity of \"facebook\" with every course\n",
    "sim_facebook = [sim_score(facebook_idx, i) for i in range(Vt.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for 'markov chains':\n",
      "MATH-332 - Applied stochastic processes : 0.7640\n",
      "MGT-484 - Applied probability & stochastic processes : 0.7424\n",
      "EE-605 - Statistical Sequence Processing : 0.7302\n",
      "COM-516 - Markov chains and algorithmic applications : 0.6065\n",
      "EE-516 - Data analysis and model classification : 0.3409\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 5 most similar courses for \"markov chains\"\n",
    "top_markov = np.argsort(sim_markov)[-5:]\n",
    "print(\"Top 5 courses for 'markov chains':\")\n",
    "for i in np.flip(top_markov):\n",
    "    course_id = document_indices[i]\n",
    "    course_name = course_dict[course_id]['name']\n",
    "    print(f'{course_id} - {course_name} : {sim_markov[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses for 'facebook':\n",
      "EE-727 - Computational Social Media : 0.9457\n",
      "EE-593 - Social media : 0.6786\n",
      "HUM-432(a) - How people learn I : 0.4248\n",
      "COM-308 - Internet analytics : 0.3889\n",
      "HUM-432(b) - How people learn II : 0.3075\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 5 most similar courses for \"facebook\"\n",
    "top_facebook = np.argsort(sim_facebook)[-5:]\n",
    "print(\"Top 5 courses for 'facebook':\")\n",
    "for i in np.flip(top_facebook):\n",
    "    course_id = document_indices[i]\n",
    "    course_name = course_dict[course_id]['name']\n",
    "    print(f'{course_id} - {course_name} : {sim_facebook[i]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous session, the result is shown as follows:  \n",
    "markov chain - top five courses with similarity score  \n",
    "('Applied stochastic processes', 0.557910816140559)  \n",
    "('Applied probability & stochastic processes', 0.541839456832587)  \n",
    "('Markov chains and algorithmic applications', 0.4210724606519116)  \n",
    "('Supply chain management', 0.39279034730463636)  \n",
    "('Mathematical models in supply chain management', 0.3076572352007134)  \n",
    "   \n",
    "facebook - top five courses with similarity score  \n",
    "('Computational Social Media', 0.18922283654097266)  \n",
    "('Composites technology', 0.0)  \n",
    "('Image Processing for Life Science', 0.0)  \n",
    "('Global business environment', 0.0)  \n",
    "('Electrochemical nano-bio-sensing and bio/CMOS interfaces', 0.0)   \n",
    "   \n",
    "**Markov Chains**  \n",
    "Using the Vector Space Model (VSM) for \"markov chains\" produced relevant courses with moderate similarity scores. Latent Semantic Indexing (LSI) also identified relevant courses, but with higher similarity scores, indicating a better capture of related topics.  \n",
    "   \n",
    "**Facebook**  \n",
    "For \"facebook,\" VSM returned fewer relevant courses, some with zero similarity. LSI performed better, identifying more courses related to social media with higher similarity scores, showing improved semantic understanding.   \n",
    "   \n",
    "And for both “Markov Chains” and “Facebook”, the Top 1 courses with the highest similiraty score are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose cosine similarity to determine the similarity between two documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cosine similarity function\n",
    "def cos_sim(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (norm(vec1, 2) * norm(vec2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the course \"COM-308\"\n",
    "com_idx = np.where(document_indices == \"COM-308\")[0][0]\n",
    "\n",
    "# Get the latent-space vector for COM-308\n",
    "com_vec = S * Vt[:, com_idx]\n",
    "\n",
    "# Compute the similarity of COM-308 with every other course\n",
    "sims = []\n",
    "for i in range(Vt.shape[1]):\n",
    "    if i != com_idx:  # Exclude the course itself\n",
    "        vec = S * Vt[:, i]\n",
    "        sim = cos_sim(com_vec, vec)\n",
    "        sims.append((i, sim))\n",
    "\n",
    "# Sort the courses by similarity score in descending order\n",
    "sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Retrieve the 5 most similar courses to COM-308\n",
    "top_5_courses = sims[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listed below are the top 5 classes most similar to COM-308:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses most similar to COM-308:\n",
      "EE-558 - A Network Tour of Data Science : 0.6277\n",
      "CS-423 - Distributed information systems : 0.5555\n",
      "CS-401 - Applied data analysis : 0.5472\n",
      "EE-727 - Computational Social Media : 0.5153\n",
      "COM-512 - Networks out of control : 0.5138\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 courses most similar to COM-308:\")\n",
    "for idx, sim in top_5_courses:\n",
    "    course_id = document_indices[idx]\n",
    "    course_name = course_dict[course_id]['name']\n",
    "    print(f'{course_id} - {course_name} : {sim:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
