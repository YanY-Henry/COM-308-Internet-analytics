{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *X*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Linqi Liu*\n",
    "* *Yifei Song*\n",
    "* *Ying Xu Dempster Tay*\n",
    "* *Yuhang Yan*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from utils import load_json\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "courses[0]: {'courseId': 'MSE-440', 'name': 'Composites technology', 'description': 'latest develop process gener organ composit discuss nanocomposit adapt composit present product develop cost analysi studi market practic team work basic composit materi process composit design composit structur current develop nanocomposit composit biocomposit adapt composit applic drive forc market cost analysi aerospac keyword composit applic nanocomposit biocomposit adapt composit design cost prerequisit requir notion polym recommend polym composit propos suitabl product perform criteria product composit part appli basic equat process mechan properti model composit materi discuss main type composit applic transvers skill work methodolog task gener domain specif IT resourc tool commun effect profession disciplin evalu perform team receiv respond appropri feedback teach cathedra invit speaker group session exercis work project expect activ attend lectur design composit part bibliographi search assess written exam report oral present class'} \n",
      "\n",
      "course_ids[:5]: ['MSE-440', 'BIO-695', 'FIN-523', 'MICRO-614', 'ME-231(a)'] \n",
      "\n",
      "terms[:5]: ['approxim', 'analysi', 'divers', 'matanya', 'refriger']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "courses = load_json('data/courses_processed.txt')\n",
    "course_ids = [x['courseId'] for x in courses]\n",
    "terms = np.load('terms_indices.npy', allow_pickle=True).tolist()\n",
    "\n",
    "print('courses[0]:', courses[0], '\\n')\n",
    "print('course_ids[:5]:', course_ids[:5], '\\n')\n",
    "print('terms[:5]:', terms[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "courses_rdd: PythonRDD[3] at RDD at PythonRDD.scala:54\n"
     ]
    }
   ],
   "source": [
    "# Transfer the data to RDD format\n",
    "courses_rdd = sc.parallelize(courses).map(\n",
    "    lambda x: [course_ids.index(x['courseId']), Vectors.dense([x['description'].split(\" \").count(t) for t in terms])]\n",
    ")\n",
    "\n",
    "print('courses_rdd:', courses_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LDA model\n",
    "lda_model = LDA.train(courses_rdd, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d796105454e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_virtualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Virtualize the model\n",
    "def model_virtualization(model):\n",
    "    lda_topic = model.describeTopics(maxTermsPerTopic=10)\n",
    "    for i, topics in enumerate(lda_topic):\n",
    "        print(f'Topic {i+1}:')\n",
    "        print([terms[topic] for topic in topics[0]])\n",
    "        \n",
    "model_virtualization(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: Chemical Processes\n",
      "Topic 2: Management and Optimization\n",
      "Topic 3: Materials and Electronics\n",
      "Topic 4: Optics and Computation\n",
      "Topic 5: Architecture and Urban Development\n",
      "Topic 6: Statistical Analysis and Signal Processing\n",
      "Topic 7: Electronics and Material Properties\n",
      "Topic 8: Cellular Biology\n",
      "Topic 9: Project Management and Research Skills\n",
      "Topic 10: Energy and Thermodynamics\n"
     ]
    }
   ],
   "source": [
    "# Manually add labels to topics\n",
    "labels = [\n",
    "    'Chemical Processes',\n",
    "    'Management and Optimization',\n",
    "    'Materials and Electronics',\n",
    "    'Optics and Computation',\n",
    "    'Architecture and Urban Development',\n",
    "    'Statistical Analysis and Signal Processing',\n",
    "    'Electronics and Material Properties',\n",
    "    'Cellular Biology',\n",
    "    'Project Management and Research Skills',\n",
    "    'Energy and Thermodynamics'\n",
    "]\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f'Topic {i+1}: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compared with LSI:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and β = 1.01, and vary α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_a(a, b=1.01, k=10):\n",
    "    print(f'k = {k}, a = {a}, b = {b}\\n')\n",
    "    lda_model = LDA.train(courses_rdd, docConcentration=a, topicConcentration=b, k=k)\n",
    "    model_virtualization(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 1.01, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['analysi', 'program', 'exercis', 'system', 'lectur', 'linear', 'optim', 'model', 'comput', 'learn']\n",
      "Topic 2:\n",
      "['present', 'microscopi', 'electron', 'research', 'field', 'scienc', 'semest', 'lectur', 'discuss', 'materi']\n",
      "Topic 3:\n",
      "['data', 'network', 'algorithm', 'theori', 'comput', 'model', 'problem', 'lectur', 'probabl', 'exercis']\n",
      "Topic 4:\n",
      "['model', 'process', 'imag', 'circuit', 'signal', 'basic', 'statist', 'system', 'digit', 'analysi']\n",
      "Topic 5:\n",
      "['biolog', 'report', 'project', 'protein', 'scientif', 'cell', 'experiment', 'experi', 'molecular', 'assess']\n",
      "Topic 6:\n",
      "['optic', 'model', 'physic', 'applic', 'mechan', 'sensor', 'magnet', 'devic', 'quantum', 'materi']\n",
      "Topic 7:\n",
      "['model', 'risk', 'price', 'stochast', 'polici', 'financi', 'market', 'analysi', 'assess', 'introduct']\n",
      "Topic 8:\n",
      "['process', 'chemistri', 'chemic', 'engin', 'mass', 'exercis', 'water', 'product', 'theori', 'assess']\n",
      "Topic 9:\n",
      "['project', 'work', 'assess', 'present', 'plan', 'evalu', 'develop', 'manag', 'skill', 'group']\n",
      "Topic 10:\n",
      "['energi', 'materi', 'cell', 'properti', 'mechan', 'reaction', 'thermodynam', 'structur', 'chemic', 'equat']\n"
     ]
    }
   ],
   "source": [
    "a = 1.01\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 2.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['model', 'architectur', 'problem', 'semest', 'optim', 'work', 'mathemat', 'method', 'numer', 'studi']\n",
      "Topic 2:\n",
      "['optic', 'theori', 'electron', 'basic', 'quantum', 'principl', 'microscopi', 'imag', 'applic', 'techniqu']\n",
      "Topic 3:\n",
      "['circuit', 'design', 'analysi', 'model', 'space', 'digit', 'process', 'integr', 'reactor', 'assess']\n",
      "Topic 4:\n",
      "['model', 'concept', 'flow', 'energi', 'dynam', 'equat', 'process', 'thermodynam', 'mechan', 'structur']\n",
      "Topic 5:\n",
      "['project', 'data', 'report', 'comput', 'scientif', 'assess', 'research', 'present', 'program', 'skill']\n",
      "Topic 6:\n",
      "['materi', 'cell', 'devic', 'applic', 'organ', 'properti', 'electron', 'magnet', 'structur', 'lectur']\n",
      "Topic 7:\n",
      "['learn', 'technolog', 'manag', 'work', 'present', 'develop', 'teach', 'risk', 'assess', 'lectur']\n",
      "Topic 8:\n",
      "['chemic', 'chemistri', 'biolog', 'present', 'reaction', 'assess', 'imag', 'process', 'activ', 'keyword']\n",
      "Topic 9:\n",
      "['model', 'assess', 'evalu', 'present', 'class', 'materi', 'plan', 'case', 'lectur', 'project']\n",
      "Topic 10:\n",
      "['model', 'process', 'signal', 'analysi', 'control', 'linear', 'exercis', 'energi', 'statist', 'filter']\n"
     ]
    }
   ],
   "source": [
    "a = 2.0\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['program', 'learn', 'algorithm', 'teach', 'optim', 'comput', 'data', 'assess', 'system', 'exercis']\n",
      "Topic 2:\n",
      "['cell', 'biolog', 'molecular', 'research', 'present', 'protein', 'discuss', 'scientif', 'develop', 'project']\n",
      "Topic 3:\n",
      "['model', 'structur', 'analysi', 'mechan', 'energi', 'problem', 'assess', 'concept', 'studi', 'case']\n",
      "Topic 4:\n",
      "['project', 'present', 'plan', 'assess', 'group', 'work', 'develop', 'skill', 'semest', 'inform']\n",
      "Topic 5:\n",
      "['chemic', 'engin', 'lectur', 'process', 'problem', 'concept', 'space', 'analysi', 'assess', 'exercis']\n",
      "Topic 6:\n",
      "['imag', 'present', 'technolog', 'flow', 'develop', 'assess', 'polici', 'lectur', 'innov', 'evalu']\n",
      "Topic 7:\n",
      "['electron', 'optic', 'circuit', 'devic', 'laser', 'microscopi', 'organ', 'architectur', 'techniqu', 'imag']\n",
      "Topic 8:\n",
      "['data', 'model', 'report', 'analysi', 'statist', 'process', 'stochast', 'time', 'probabl', 'practic']\n",
      "Topic 9:\n",
      "['materi', 'energi', 'properti', 'applic', 'magnet', 'power', 'physic', 'sensor', 'state', 'phase']\n",
      "Topic 10:\n",
      "['model', 'theori', 'process', 'basic', 'comput', 'control', 'exercis', 'linear', 'perform', 'system']\n"
     ]
    }
   ],
   "source": [
    "a = 6.0\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 10.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['report', 'model', 'problem', 'equat', 'numer', 'theori', 'optim', 'flow', 'project', 'comput']\n",
      "Topic 2:\n",
      "['system', 'architectur', 'engin', 'process', 'technolog', 'product', 'lectur', 'materi', '2', 'project']\n",
      "Topic 3:\n",
      "['present', 'biolog', 'paper', 'optic', 'assess', 'discuss', 'oral', 'develop', 'scientif', 'evalu']\n",
      "Topic 4:\n",
      "['teach', 'learn', 'electron', 'imag', 'data', 'magnet', 'applic', 'basic', 'scienc', 'assess']\n",
      "Topic 5:\n",
      "['model', 'control', 'system', 'assess', 'techniqu', 'signal', 'analysi', 'process', 'exercis', 'robot']\n",
      "Topic 6:\n",
      "['cell', 'data', 'assess', 'project', 'concept', 'present', 'molecular', 'metal', 'biolog', 'basic']\n",
      "Topic 7:\n",
      "['process', 'present', 'engin', 'assess', 'manag', 'model', 'chemistri', 'exercis', 'environment', 'work']\n",
      "Topic 8:\n",
      "['model', 'optic', 'stochast', 'introduct', 'deriv', 'assess', 'lectur', 'analysi', 'exam', 'protein']\n",
      "Topic 9:\n",
      "['structur', 'mechan', 'materi', 'process', 'mass', 'energi', 'applic', 'properti', 'basic', 'reaction']\n",
      "Topic 10:\n",
      "['work', 'develop', 'semest', 'research', 'project', 'present', 'evalu', 'assess', 'polici', 'studi']\n"
     ]
    }
   ],
   "source": [
    "a = 10.0\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 20.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['process', 'model', 'basic', 'assess', 'concept', 'chemic', 'exercis', 'analysi', 'lectur', 'activ']\n",
      "Topic 2:\n",
      "['model', 'system', 'assess', 'analysi', 'lectur', 'robot', 'concept', 'exercis', 'control', 'basic']\n",
      "Topic 3:\n",
      "['assess', 'data', 'model', 'analysi', 'project', 'process', 'present', 'evalu', 'develop', 'work']\n",
      "Topic 4:\n",
      "['energi', 'assess', 'magnet', 'model', 'process', 'present', 'materi', 'project', 'concept', 'basic']\n",
      "Topic 5:\n",
      "['assess', 'model', 'project', 'process', 'present', 'analysi', 'data', 'applic', 'report', 'basic']\n",
      "Topic 6:\n",
      "['engin', 'structur', 'model', 'lectur', 'present', 'assess', 'process', 'week', 'concept', 'basic']\n",
      "Topic 7:\n",
      "['optic', 'materi', 'devic', 'model', 'assess', 'applic', 'basic', 'lectur', 'concept', 'electron']\n",
      "Topic 8:\n",
      "['model', 'risk', 'stochast', 'assess', 'probabl', 'analysi', 'theori', 'linear', 'optim', 'price']\n",
      "Topic 9:\n",
      "['architectur', 'project', 'work', 'assess', 'present', 'develop', 'research', 'semest', 'lectur', 'plan']\n",
      "Topic 10:\n",
      "['assess', 'polici', 'present', 'cell', 'project', 'evalu', 'model', 'data', 'teach', 'activ']\n"
     ]
    }
   ],
   "source": [
    "a = 20.0\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 100.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['model', 'assess', 'process', 'present', 'project', 'lectur', 'analysi', 'concept', 'basic', 'teach']\n",
      "Topic 2:\n",
      "['model', 'assess', 'process', 'lectur', 'present', 'concept', 'basic', 'project', 'exercis', 'analysi']\n",
      "Topic 3:\n",
      "['model', 'assess', 'lectur', 'process', 'analysi', 'project', 'present', 'basic', 'work', 'concept']\n",
      "Topic 4:\n",
      "['model', 'assess', 'process', 'present', 'analysi', 'lectur', 'basic', 'concept', 'project', 'teach']\n",
      "Topic 5:\n",
      "['model', 'assess', 'analysi', 'present', 'basic', 'concept', 'lectur', 'work', 'process', 'project']\n",
      "Topic 6:\n",
      "['model', 'assess', 'present', 'project', 'process', 'analysi', 'lectur', 'basic', 'concept', 'work']\n",
      "Topic 7:\n",
      "['model', 'assess', 'present', 'lectur', 'project', 'process', 'analysi', 'basic', 'exercis', 'work']\n",
      "Topic 8:\n",
      "['model', 'assess', 'present', 'lectur', 'process', 'project', 'analysi', 'basic', 'work', 'teach']\n",
      "Topic 9:\n",
      "['model', 'assess', 'present', 'basic', 'analysi', 'lectur', 'project', 'process', 'concept', 'work']\n",
      "Topic 10:\n",
      "['model', 'assess', 'process', 'present', 'basic', 'analysi', 'lectur', 'concept', 'project', 'work']\n"
     ]
    }
   ],
   "source": [
    "a = 100.0\n",
    "test_with_a(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high α value leads to a uniform distribution of topics across documents, where each topic is equally represented. When α=100, general terms dominate the topics, present in almost all documents. Even with α=20, some specific words still persist, but the overall effect remains similar.\n",
    "\n",
    "No notable difference is seen in topics for α values {1.01, 2, 5}, with the top terms staying consistent. However, for α=10, we begin to see specific domain terms diminish and relevance scores decrease, approaching a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and α = 6, and vary β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_b(b, a=6.0, k=10):\n",
    "    print(f'k = {k}, a = {a}, b = {b}\\n')\n",
    "    lda_model = LDA.train(courses_rdd, docConcentration=a, topicConcentration=b, k=k)\n",
    "    model_virtualization(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['learn', 'assess', 'teach', 'evalu', 'work', 'structur', 'inform', 'group', 'innov', 'week']\n",
      "Topic 2:\n",
      "['imag', 'process', 'architectur', 'magnet', 'digit', 'project', 'model', 'quantum', 'visual', 'work']\n",
      "Topic 3:\n",
      "['assess', 'energi', 'present', 'properti', 'physic', 'materi', 'network', 'metal', 'electr', 'teach']\n",
      "Topic 4:\n",
      "['cell', 'molecular', 'energi', 'electron', 'materi', 'biolog', 'mechan', 'discuss', 'spectroscopi', 'principl']\n",
      "Topic 5:\n",
      "['present', 'biolog', 'develop', 'chemic', 'assess', 'activ', 'manag', 'chemistri', 'process', 'work']\n",
      "Topic 6:\n",
      "['model', 'theori', 'probabl', 'optim', 'stochast', 'market', 'time', 'deriv', 'risk', 'introduct']\n",
      "Topic 7:\n",
      "['problem', 'numer', 'equat', 'analysi', 'solv', 'simul', 'function', 'comput', 'flow', 'exercis']\n",
      "Topic 8:\n",
      "['electron', 'applic', 'materi', 'mechan', 'introduct', 'techniqu', 'control', 'model', 'process', 'basic']\n",
      "Topic 9:\n",
      "['project', 'report', 'optic', 'research', 'plan', 'scientif', 'evalu', 'system', 'engin', 'experi']\n",
      "Topic 10:\n",
      "['model', 'statist', 'signal', 'analysi', 'data', 'linear', 'process', 'basic', 'algorithm', 'program']\n"
     ]
    }
   ],
   "source": [
    "b = 1.01\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 2.0\n",
      "\n",
      "Topic 1:\n",
      "['model', 'structur', 'assess', 'data', 'week', 'problem', 'analysi', 'project', 'lectur', 'theori']\n",
      "Topic 2:\n",
      "['electron', 'optic', 'imag', 'microscopi', 'assess', 'lectur', 'principl', 'biolog', 'protein', 'model']\n",
      "Topic 3:\n",
      "['model', 'theori', 'basic', 'process', 'stochast', 'assess', 'probabl', 'linear', 'optim', 'statist']\n",
      "Topic 4:\n",
      "['optic', 'model', 'assess', 'basic', 'lectur', 'present', 'concept', 'exercis', 'applic', 'activ']\n",
      "Topic 5:\n",
      "['model', 'basic', 'exercis', 'reaction', 'comput', 'process', 'assess', 'concept', 'theori', 'analysi']\n",
      "Topic 6:\n",
      "['model', 'process', 'equat', 'flow', 'exercis', 'engin', 'concept', 'assess', 'basic', 'numer']\n",
      "Topic 7:\n",
      "['materi', 'applic', 'properti', 'mechan', 'assess', 'physic', 'present', 'structur', 'lectur', 'devic']\n",
      "Topic 8:\n",
      "['technolog', 'energi', 'project', 'present', 'evalu', 'report', 'assess', 'polici', 'industri', 'plan']\n",
      "Topic 9:\n",
      "['cell', 'project', 'develop', 'assess', 'present', 'learn', 'work', 'biolog', 'evalu', 'teach']\n",
      "Topic 10:\n",
      "['process', 'signal', 'data', 'model', 'analysi', 'assess', 'project', 'system', 'present', 'network']\n"
     ]
    }
   ],
   "source": [
    "b = 2.0\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 5.0\n",
      "\n",
      "Topic 1:\n",
      "['optic', 'model', 'assess', 'lectur', 'analysi', 'present', 'basic', 'concept', 'process', 'activ']\n",
      "Topic 2:\n",
      "['assess', 'present', 'model', 'project', 'process', 'work', 'lectur', 'concept', 'evalu', 'activ']\n",
      "Topic 3:\n",
      "['model', 'assess', 'data', 'analysi', 'project', 'present', 'lectur', 'process', 'basic', 'work']\n",
      "Topic 4:\n",
      "['model', 'assess', 'project', 'process', 'present', 'analysi', 'work', 'data', 'lectur', 'concept']\n",
      "Topic 5:\n",
      "['model', 'assess', 'present', 'analysi', 'lectur', 'project', 'concept', 'basic', 'work', 'process']\n",
      "Topic 6:\n",
      "['model', 'assess', 'analysi', 'process', 'basic', 'lectur', 'concept', 'present', 'exercis', 'system']\n",
      "Topic 7:\n",
      "['model', 'basic', 'assess', 'process', 'applic', 'materi', 'lectur', 'concept', 'prerequisit', 'analysi']\n",
      "Topic 8:\n",
      "['model', 'assess', 'basic', 'lectur', 'process', 'materi', 'concept', 'applic', 'exercis', 'theori']\n",
      "Topic 9:\n",
      "['assess', 'present', 'project', 'process', 'lectur', 'model', 'work', 'evalu', 'activ', 'concept']\n",
      "Topic 10:\n",
      "['model', 'assess', 'process', 'present', 'materi', 'lectur', 'concept', 'basic', 'applic', 'analysi']\n"
     ]
    }
   ],
   "source": [
    "b = 5.0\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 10.0\n",
      "\n",
      "Topic 1:\n",
      "['model', 'assess', 'present', 'analysi', 'process', 'lectur', 'project', 'concept', 'basic', 'work']\n",
      "Topic 2:\n",
      "['model', 'assess', 'process', 'present', 'lectur', 'basic', 'analysi', 'concept', 'project', 'work']\n",
      "Topic 3:\n",
      "['model', 'assess', 'process', 'lectur', 'basic', 'present', 'analysi', 'concept', 'project', 'work']\n",
      "Topic 4:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'basic', 'project', 'analysi', 'concept', 'work']\n",
      "Topic 5:\n",
      "['model', 'assess', 'process', 'present', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n",
      "Topic 6:\n",
      "['model', 'assess', 'process', 'present', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n",
      "Topic 7:\n",
      "['model', 'assess', 'project', 'present', 'analysi', 'lectur', 'process', 'work', 'data', 'concept']\n",
      "Topic 8:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'basic', 'project', 'analysi', 'concept', 'work']\n",
      "Topic 9:\n",
      "['model', 'assess', 'process', 'lectur', 'present', 'basic', 'analysi', 'project', 'concept', 'work']\n",
      "Topic 10:\n",
      "['model', 'assess', 'present', 'analysi', 'lectur', 'process', 'project', 'basic', 'concept', 'work']\n"
     ]
    }
   ],
   "source": [
    "b = 10.0\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 20.0\n",
      "\n",
      "Topic 1:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 2:\n",
      "['model', 'assess', 'process', 'present', 'lectur', 'basic', 'analysi', 'project', 'concept', 'work']\n",
      "Topic 3:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n",
      "Topic 4:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n",
      "Topic 5:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'project', 'analysi', 'basic', 'concept', 'work']\n",
      "Topic 6:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 7:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 8:\n",
      "['model', 'assess', 'present', 'process', 'project', 'lectur', 'analysi', 'basic', 'concept', 'work']\n",
      "Topic 9:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n",
      "Topic 10:\n",
      "['model', 'assess', 'process', 'present', 'lectur', 'analysi', 'basic', 'project', 'concept', 'work']\n"
     ]
    }
   ],
   "source": [
    "b = 20.0\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, a = 6.0, b = 100.0\n",
      "\n",
      "Topic 1:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 2:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 3:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 4:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 5:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 6:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 7:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 8:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 9:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n",
      "Topic 10:\n",
      "['model', 'assess', 'present', 'process', 'lectur', 'analysi', 'project', 'basic', 'concept', 'work']\n"
     ]
    }
   ],
   "source": [
    "b = 100.0\n",
    "test_with_b(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, adjusting the value of β in the LDA model impacts the similarity between topics. As β increases, topics tend to become more alike, while decreasing β results in more distinct and diverse topics. This phenomenon arises from the role of β in shaping the prior distribution of topics across terms. Larger β values promote smoother inferred distributions, fostering uniformity among topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As EPFL has 20 different sessions, we choose $k=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want the distribution of topics per document not to be not very close to uniform, we choose small values for $a=b=1.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1.01, 1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 20, a = 1.01, b = 1.01\n",
      "\n",
      "Topic 1:\n",
      "['project', 'assess', 'plan', 'skill', 'present', 'evalu', 'work', 'group', 'research', 'report']\n",
      "Topic 2:\n",
      "['control', 'theori', 'model', 'probabl', 'time', '2', 'applic', 'hour', 'exam', 'studi']\n",
      "Topic 3:\n",
      "['model', 'price', 'stochast', 'fourier', 'deriv', 'financi', 'financ', 'risk', 'market', 'introduct']\n",
      "Topic 4:\n",
      "['optic', 'laser', 'imag', 'light', 'principl', 'basic', 'measur', 'process', 'microscopi', 'applic']\n",
      "Topic 5:\n",
      "['present', 'paper', 'biolog', 'protein', 'discuss', 'research', 'field', 'lectur', 'assess', 'report']\n",
      "Topic 6:\n",
      "['reaction', 'mechan', 'molecular', 'structur', 'organ', 'properti', 'solut', 'basic', 'assess', 'state']\n",
      "Topic 7:\n",
      "['materi', 'chemistri', 'magnet', 'applic', 'metal', 'properti', 'field', 'chemic', 'physic', 'reaction']\n",
      "Topic 8:\n",
      "['report', 'project', 'evalu', 'semest', 'activ', 'scientif', 'student', 'supervis', 'work', 'laboratori']\n",
      "Topic 9:\n",
      "['risk', 'assess', 'present', 'develop', 'busi', 'evalu', 'case', 'manag', 'speech', 'process']\n",
      "Topic 10:\n",
      "['chemic', 'treatment', 'process', 'assess', 'physic', 'chemistri', 'exercis', 'spectroscopi', 'biolog', 'activ']\n",
      "Topic 11:\n",
      "['devic', 'basic', 'sensor', 'process', 'concept', 'mechan', 'exampl', 'assess', 'engin', 'integr']\n",
      "Topic 12:\n",
      "['comput', 'program', 'model', 'algorithm', 'exercis', 'visual', 'mathemat', 'numer', 'theori', 'basic']\n",
      "Topic 13:\n",
      "['architectur', 'work', 'develop', 'industri', 'product', 'urban', 'build', 'present', 'project', 'semest']\n",
      "Topic 14:\n",
      "['energi', 'process', 'power', 'control', 'convers', 'commun', 'model', 'robot', 'code', 'integr']\n",
      "Topic 15:\n",
      "['electron', 'materi', 'structur', 'mechan', 'polici', 'properti', 'microscopi', 'technolog', 'physic', 'scienc']\n",
      "Topic 16:\n",
      "['cell', 'transfer', 'heat', 'reactor', 'flow', 'cancer', 'molecular', 'nuclear', 'fluid', 'principl']\n",
      "Topic 17:\n",
      "['data', 'model', 'analysi', 'linear', 'statist', 'problem', 'flow', 'algorithm', 'basic', 'lectur']\n",
      "Topic 18:\n",
      "['model', 'physic', 'process', 'equat', 'problem', 'numer', 'basic', 'random', 'solv', 'measur']\n",
      "Topic 19:\n",
      "['circuit', 'stabil', 'quantum', 'structur', 'design', 'dynam', 'theori', 'exercis', 'model', 'week']\n",
      "Topic 20:\n",
      "['system', 'model', 'manag', 'engin', 'languag', 'concept', 'design', 'assess', 'tool', 'lectur']\n"
     ]
    }
   ],
   "source": [
    "print(f'k = {k}, a = {a}, b = {b}\\n')\n",
    "lda_epfl = LDA.train(courses_rdd, docConcentration=a, topicConcentration=b, k=k)\n",
    "model_virtualization(lda_epfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add labels to topics\n",
    "labels = [\n",
    "    'Project',\n",
    "    'Statistical Mechanics',\n",
    "    'Finance',\n",
    "    'Optics',\n",
    "    'Biology',\n",
    "    'Chemistry',\n",
    "    'Material',\n",
    "    'Project',\n",
    "    'Risk Management',\n",
    "    'Sciense',\n",
    "    'Sensor Design',\n",
    "    'Computer Science',\n",
    "    'Architecture',\n",
    "    'Energy',\n",
    "    'Electronic Engineering',\n",
    "    'Bio Engineering',\n",
    "    'Data Science',\n",
    "    'Physice',\n",
    "    'Quantum Theory',\n",
    "    'Project'\n",
    "]\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f'Topic {i+1}: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia content covers a lot of areas, and since memory is limited, we chose $k=30$. Also, since we want to filter out more representative keywords, we still chose small values for $a=b=1.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "wiki_RDD = sc.textFile('/ix/wikipedia-for-schools.txt').map(json.loads)\n",
    "wikipage_RDD = wiki_RDD.map(lambda p: p['page_id']).distinct()\n",
    "N = wikipage_RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record every page\n",
    "pageID = list(dict(zip(wikipage_RDD.collect(), range(N))).values())\n",
    "\n",
    "# Record all words\n",
    "words_RDD = wiki_RDD.flatMap(lambda p: p[\"tokens\"]).distinct()\n",
    "M = words_RDD.count() \n",
    "\n",
    "# Record all terms\n",
    "terms = dict(zip(words_RDD.collect(), range(M)))\n",
    "vectorized_term = np.vectorize(lambda x: terms[x])\n",
    "termID = {v: k for k, v in terms.items()}\n",
    "\n",
    "# Reduce wikipedia RDD with only indexes\n",
    "red_wiki_RDD = wiki_RDD.map(lambda c: (pageID[c[\"page_id\"]], vectorized_term(c[\"tokens\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_vector(doc):\n",
    "    vector = {}\n",
    "    for term in doc[1]:\n",
    "        vector[term] = vector.get(term, 0) + 1\n",
    "    return (doc[0], Vectors.sparse(M, vector))\n",
    "\n",
    "# Build the term-document matrix\n",
    "term_doc_matrix = red_wiki_RDD.map(lambda x: doc_to_vector(x)).map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "['games', 'game', 'players', 'world', 'time', 'olympic', '–', 'cup', 'player', 'events']\n",
      "Topic 2:\n",
      "['theory', 'number', '=', 'numbers', 'work', 'set', 'called', 'form', 'written', 'century']\n",
      "Topic 3:\n",
      "['city', '·', 'centre', 'century', 'law', 'population', 'system', 'government', 'state', 'years']\n",
      "Topic 4:\n",
      "['blood', 'people', 'health', 'cancer', 'medical', 'treatment', 'risk', 'patients', 'high', 'years']\n",
      "Topic 5:\n",
      "['eruption', 'years', 'comet', 'lava', 'volcanic', 'volcano', 'india', 'soil', 'large', 'time']\n",
      "Topic 6:\n",
      "['island', 'islands', 'european', 'city', 'population', 'country', 'north', 'south', 'ireland', 'east']\n",
      "Topic 7:\n",
      "['south', 'lake', 'mi', 'area', 'river', 'city', 'oil', 'water', 'population', 'north']\n",
      "Topic 8:\n",
      "['gas', 'lens', 'game', 'time', 'earth', 'lenses', 'water', 'number', 'ds', 'haiku']\n",
      "Topic 9:\n",
      "['music', 'instruments', 'painting', 'art', 'made', 'popular', 'instrument', 'set', 'bass', 'style']\n",
      "Topic 10:\n",
      "['american', '–', 'calendar', 'january', 'march', 'february', 'july', 'april', 'june', 'december']\n",
      "Topic 11:\n",
      "['computer', 'software', 'oil', 'language', 'acid', 'system', 'internet', 'apple', '^', 'version']\n",
      "Topic 12:\n",
      "['energy', 'water', 'mass', 'light', 'earth', 'surface', 'chemical', 'form', 'temperature', 'solar']\n",
      "Topic 13:\n",
      "['film', 'john', 'england', 'series', 'time', 'london', '–', 'years', 'house', 'george']\n",
      "Topic 14:\n",
      "['government', 'state', 'rights', 'states', 'china', 'united', 'president', 'national', 'city', 'republic']\n",
      "Topic 15:\n",
      "['river', 'sea', 'lake', 'area', 'north', 'world', 'large', 'south', 'years', 'al']\n",
      "Topic 16:\n",
      "['bc', 'gods', 'egyptian', 'horse', 'god', 'egypt', 'mythology', 'modern', 'greek', 'temple']\n",
      "Topic 17:\n",
      "['war', 'british', 'american', 'united', 'german', 'september', 'august', 'states', 'july', 'army']\n",
      "Topic 18:\n",
      "['ice', 'space', 'war', 'nuclear', 'soviet', 'forces', 'weapons', 'time', 'force', 'mission']\n",
      "Topic 19:\n",
      "['system', 'systems', 'energy', 'information', 'distribution', 'data', 'number', 'dna', 'engine', 'process']\n",
      "Topic 20:\n",
      "['company', '$', 'war', 'market', 'states', 'world', 'united', 'government', 'system', 'japanese']\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic 1:\\n['games', 'game', 'players', 'world', 'time', 'olympic', '–', 'cup', 'player', 'events']\\nTopic 2:\\n['theory', 'number', '=', 'numbers', 'work', 'set', 'called', 'form', 'written', 'century']\\nTopic 3:\\n['city', '·', 'centre', 'century', 'law', 'population', 'system', 'government', 'state', 'years']\\nTopic 4:\\n['blood', 'people', 'health', 'cancer', 'medical', 'treatment', 'risk', 'patients', 'high', 'years']\\nTopic 5:\\n['eruption', 'years', 'comet', 'lava', 'volcanic', 'volcano', 'india', 'soil', 'large', 'time']\\nTopic 6:\\n['island', 'islands', 'european', 'city', 'population', 'country', 'north', 'south', 'ireland', 'east']\\nTopic 7:\\n['south', 'lake', 'mi', 'area', 'river', 'city', 'oil', 'water', 'population', 'north']\\nTopic 8:\\n['gas', 'lens', 'game', 'time', 'earth', 'lenses', 'water', 'number', 'ds', 'haiku']\\nTopic 9:\\n['music', 'instruments', 'painting', 'art', 'made', 'popular', 'instrument', 'set', 'bass', 'style']\\nTopic 10:\\n['american', '–', 'calendar', 'january', 'march', 'february', 'july', 'april', 'june', 'december']\\nTopic 11:\\n['computer', 'software', 'oil', 'language', 'acid', 'system', 'internet', 'apple', '^', 'version']\\nTopic 12:\\n['energy', 'water', 'mass', 'light', 'earth', 'surface', 'chemical', 'form', 'temperature', 'solar']\\nTopic 13:\\n['film', 'john', 'england', 'series', 'time', 'london', '–', 'years', 'house', 'george']\\nTopic 14:\\n['government', 'state', 'rights', 'states', 'china', 'united', 'president', 'national', 'city', 'republic']\\nTopic 15:\\n['river', 'sea', 'lake', 'area', 'north', 'world', 'large', 'south', 'years', 'al']\\nTopic 16:\\n['bc', 'gods', 'egyptian', 'horse', 'god', 'egypt', 'mythology', 'modern', 'greek', 'temple']\\nTopic 17:\\n['war', 'british', 'american', 'united', 'german', 'september', 'august', 'states', 'july', 'army']\\nTopic 18:\\n['ice', 'space', 'war', 'nuclear', 'soviet', 'forces', 'weapons', 'time', 'force', 'mission']\\nTopic 19:\\n['system', 'systems', 'energy', 'information', 'distribution', 'data', 'number', 'dna', 'engine', 'process']\\nTopic 20:\\n['company', '$', 'war', 'market', 'states', 'world', 'united', 'government', 'system', 'japanese']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-2517f0d966b3>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-2517f0d966b3>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    '',\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Manually add labels to topics\n",
    "labels = [\n",
    "    \"Olympic Games\",\n",
    "    \"Maths\",\n",
    "    \"City\",\n",
    "    \"Disease\",\n",
    "    \"Geography\",\n",
    "    \"Europe\",\n",
    "    \"Population\",\n",
    "    \"Lenses and Light\",\n",
    "    \"Art\",\n",
    "    \"Calendar\",\n",
    "    \"Computers and Software\",\n",
    "    \"Earth's Energy\",\n",
    "    \"Film\",\n",
    "    \"Forms of Government\",\n",
    "    \"Rivers and Lakes\",\n",
    "    \"History\",\n",
    "    \"Months\",\n",
    "    \"Wars\",\n",
    "    \"Environment\",\n",
    "    \"Global Corporations\",\n",
    "]\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f'Topic {i+1}: {label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
