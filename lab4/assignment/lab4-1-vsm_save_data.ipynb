{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *X*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Linqi LIU\n",
    "* Yifei SONG\n",
    "* Yuhang YAN\n",
    "* Ying Xu Dempster TAY\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of courses\n",
    "\n",
    "len(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest developments in processing and the novel generations of organic composites are discussed. Nanocomposites, adaptive composites and biocomposites are presented. Product development, cost analysis and study of new markets are practiced in team work. Content Basics of composite materialsConstituentsProcessing of compositesDesign of composite structures Current developmentNanocomposites Textile compositesBiocompositesAdaptive composites ApplicationsDriving forces and marketsCost analysisAerospaceAutomotiveSport Keywords Composites - Applications - Nanocomposites - Biocomposites - Adaptive composites - Design - Cost Learning Prerequisites Required courses Notion of polymers Recommended courses Polymer Composites Learning Outcomes By the end of the course, the student must be able to: Propose suitable design, production and performance criteria for the production of a composite partApply the basic equations for process and mechanical properties modelling for composite materialsDiscuss the main types of composite applications Transversal skills Use a work methodology appropriate to the task.Use both general and domain specific IT resources and toolsCommunicate effectively with professionals from other disciplines.Evaluate one's own performance in the team, receive and respond appropriately to feedback. Teaching methods Ex cathedra and invited speakers Group sessions with exercises or work on the project Expected student activities Attendance at lectures Design of a composite part, bibliography search   Assessment methods Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# First course description\n",
    "\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The latest developments in processing and the novel generations of organic composites are discussed.  Nanocomposites, adaptive composites and biocomposites are presented.  Product development, cost analysis and study of new markets are practiced in team work.  Content  Basics of composite materials Constituents Processing of composites Design of composite structures  Current development Nanocomposites  Textile composites Biocomposites Adaptive composites  Applications Driving forces and markets Cost analysis Aerospace Automotive Sport  Keywords  Composites -  Applications -  Nanocomposites -  Biocomposites -  Adaptive composites -  Design -  Cost  Learning  Prerequisites  Required courses  Notion of polymers  Recommended courses  Polymer  Composites  Learning  Outcomes  By the end of the course, the student must be able to:  Propose suitable design, production and performance criteria for the production of a composite part Apply the basic equations for process and mechanical properties modelling for composite materials Discuss the main types of composite applications  Transversal skills  Use a work methodology appropriate to the task. Use both general and domain specific  IT resources and tools Communicate effectively with professionals from other disciplines. Evaluate one's own performance in the team, receive and respond appropriately to feedback.  Teaching methods  Ex cathedra and invited speakers  Group sessions with exercises or work on the project  Expected student activities  Attendance at lectures  Design of a composite part, bibliography search  Assessment methods  Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# Split connected words (eg. materialsConstituentsProcessing but not for acronyms like IT)\n",
    "\n",
    "for course in courses:\n",
    "\twords = []\n",
    "\tcurrent_word = ''\n",
    "\n",
    "\tfor word in course['description'].split():\n",
    "\t\tfor char in word:\n",
    "\t\t\t# If char is uppercase, it is the start of a new word\n",
    "\t\t\tif char.isupper():\n",
    "\t\t\t\t# Don't add word yet if it is all uppercase (acronym)\n",
    "\t\t\t\tif current_word.isupper() and len(current_word) > 0:\n",
    "\t\t\t\t\tcurrent_word += char\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# Add current word\n",
    "\t\t\t\twords.append(current_word)\n",
    "\t\t\t\tcurrent_word = char\n",
    "\t\t\telse:\n",
    "\t\t\t\tcurrent_word += char\n",
    "\n",
    "\t\twords.append(current_word)\n",
    "\t\tcurrent_word = ''\n",
    "\n",
    "\tcourse['description'] = ' '.join(words)\n",
    "\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The latest developments in processing and the novel generations of organic composites are discussed  Nanocomposites adaptive composites and biocomposites are presented  Product development cost analysis and study of new markets are practiced in team work  Content  Basics of composite materials Constituents Processing of composites Design of composite structures  Current development Nanocomposites  Textile composites Biocomposites Adaptive composites  Applications Driving forces and markets Cost analysis Aerospace Automotive Sport  Keywords  Composites   Applications   Nanocomposites   Biocomposites   Adaptive composites   Design   Cost  Learning  Prerequisites  Required courses  Notion of polymers  Recommended courses  Polymer  Composites  Learning  Outcomes  By the end of the course the student must be able to  Propose suitable design production and performance criteria for the production of a composite part Apply the basic equations for process and mechanical properties modelling for composite materials Discuss the main types of composite applications  Transversal skills  Use a work methodology appropriate to the task Use both general and domain specific  IT resources and tools Communicate effectively with professionals from other disciplines Evaluate ones own performance in the team receive and respond appropriately to feedback  Teaching methods  Ex cathedra and invited speakers  Group sessions with exercises or work on the project  Expected student activities  Attendance at lectures  Design of a composite part bibliography search  Assessment methods  Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "\n",
    "for course in courses:\n",
    "\tcourse['description'] = ''.join([char for char in course['description'] if char not in string.punctuation])\n",
    "\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest developments processing generations organic composites discussed Nanocomposites adaptive composites biocomposites presented Product development cost analysis study markets practiced team work Content Basics composite materials Constituents Processing composites Design composite structures Current development Nanocomposites Textile composites Biocomposites Adaptive composites Applications Driving forces markets Cost analysis Aerospace Automotive Sport Keywords Composites Applications Nanocomposites Biocomposites Adaptive composites Design Cost Learning Prerequisites Required courses Notion polymers Recommended courses Polymer Composites Learning Outcomes end student Propose suitable design production performance criteria production composite part Apply basic equations process mechanical properties modelling composite materials Discuss main types composite applications Transversal skills work methodology task general domain specific IT resources tools Communicate effectively professionals disciplines Evaluate performance team receive respond appropriately feedback Teaching methods cathedra invited speakers Group sessions exercises work project Expected student activities Attendance lectures Design composite part bibliography search Assessment methods Written exam report oral presentation class\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords and capitalized versions\n",
    "\n",
    "stopwords_capitalized = [s.capitalize() for s in stopwords]\n",
    "\n",
    "for course in courses:\n",
    "\tcourse['description'] = ' '.join([w for w in course['description'].split() if w not in stopwords and w not in stopwords_capitalized])\n",
    "\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18796"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check word frequency\n",
    "\n",
    "freq_dict = {}\n",
    "\n",
    "for course in courses:\n",
    "  for word in course['description'].split():\n",
    "    if word in freq_dict:\n",
    "      freq_dict[word] += 1\n",
    "    else:\n",
    "      freq_dict[word] = 1\n",
    "\n",
    "len(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('methods', 1592), ('Learning', 1239), ('student', 1177), ('Content', 835), ('courses', 757), ('systems', 697), ('end', 661), ('students', 655), ('design', 603), ('Outcomes', 600)]\n",
      "[('biocomposites', 1), ('Constituents', 1), ('Textile', 1), ('Automotive', 1), ('Sport', 1), ('photograph', 1), ('blot', 1), ('extracted', 1), ('reproducibility', 1), ('pipelines', 1)]\n"
     ]
    }
   ],
   "source": [
    "frequent_sorted = sorted(freq_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "infrequent_sorted = sorted(freq_dict.items(), key=lambda x: x[1])\n",
    "print(frequent_sorted[:10])\n",
    "print(infrequent_sorted[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9462"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose infrequent words that only appear once\n",
    "\n",
    "infrequent_sorted = [w for w in infrequent_sorted if w[1] == 1]\n",
    "len(infrequent_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists of frequent and infrequent words\n",
    "\n",
    "frequent_list = [w[0] for w in frequent_sorted[:10]]\n",
    "infrequent_list = [w[0] for w in infrequent_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest developments processing generations organic composites discussed Nanocomposites adaptive composites presented Product development cost analysis study markets practiced team work Basics composite materials Processing composites Design composite structures Current development Nanocomposites composites Biocomposites Adaptive composites Applications Driving forces markets Cost analysis Aerospace Keywords Composites Applications Nanocomposites Biocomposites Adaptive composites Design Cost Prerequisites Required Notion polymers Recommended Polymer Composites Propose suitable production performance criteria production composite part Apply basic equations process mechanical properties modelling composite materials Discuss main types composite applications Transversal skills work methodology task general domain specific IT resources tools Communicate effectively professionals disciplines Evaluate performance team receive respond appropriately feedback Teaching cathedra invited speakers Group sessions exercises work project Expected activities Attendance lectures Design composite part bibliography search Assessment Written exam report oral presentation class\n"
     ]
    }
   ],
   "source": [
    "# Remove frequent and infrequent words\n",
    "\n",
    "for course in courses:\n",
    "\tcourse['description'] = ' '.join([w for w in course['description'].split() if w not in frequent_list and w not in infrequent_list])\n",
    "\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest develop process gener organ composit discuss nanocomposit adapt composit present product develop cost analysi studi market practic team work basic composit materi process composit design composit structur current develop nanocomposit composit biocomposit adapt composit applic drive forc market cost analysi aerospac keyword composit applic nanocomposit biocomposit adapt composit design cost prerequisit requir notion polym recommend polym composit propos suitabl product perform criteria product composit part appli basic equat process mechan properti model composit materi discuss main type composit applic transvers skill work methodolog task gener domain specif IT resourc tool commun effect profession disciplin evalu perform team receiv respond appropri feedback teach cathedra invit speaker group session exercis work project expect activ attend lectur design composit part bibliographi search assess written exam report oral present class\n"
     ]
    }
   ],
   "source": [
    "# Stem the words\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for course in courses:\n",
    "\tstemmed_words = [stemmer.stem(word) for word in course['description'].split()]\n",
    "\tcourse['description'] = ' '.join(stemmed_words)\n",
    "\n",
    "print(courses[0]['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain which ones you implemented and why.\n",
    "\n",
    "1. **Remove Punctuation**: Punctuation is often irrelevant for text analysis tasks, so removing them simplifies the text and ensures consistency in tokenization.\n",
    "\n",
    "2. **Split Connected Camelcase Words**: CamelCase words are compound words written without spaces and with each word capitalized. Splitting them into individual words helps tokenize them accurately.\n",
    "\n",
    "3. **Remove Stopwords**: Stopwords don't contribute much to the context and can be safely removed to focus on content-bearing words.\n",
    "\n",
    "4. **Remove Very Frequent Words**: Very frequent words don't help distinguish between documents. Removing them reduces noise and improves model performance.\n",
    "\n",
    "5. **Remove Infrequent Words**: Infrequent words include noise or rare terms. Removing them further reduces noise and prevents overfitting.\n",
    "\n",
    "6. **Stem the Words**: Stemming reduces words to their root forms, simplifying analysis by collapsing inflected forms to a common representation and improving the effectiveness of text mining algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20', '30', '50', 'acquir', 'activ', 'ad', 'ad', 'advertis', 'algebra', 'algebra', 'algorithm', 'algorithm', 'analysi', 'analyt', 'analyt', 'analyz', 'applic', 'applic', 'assess', 'auction', 'auction', 'balanc', 'base', 'base', 'basic', 'basic', 'basic', 'cathedra', 'chain', 'class', 'class', 'class', 'cloud', 'cluster', 'cluster', 'collect', 'com300', 'combin', 'commun', 'commun', 'commun', 'comput', 'comput', 'concept', 'concept', 'concret', 'coverag', 'current', 'data', 'data', 'data', 'data', 'data', 'data', 'dataset', 'dataset', 'decad', 'dedic', 'design', 'detect', 'detect', 'develop', 'dimension', 'draw', 'ecommerc', 'ecommerc', 'effect', 'effici', 'exam', 'expect', 'explor', 'explor', 'explor', 'explor', 'explor', 'field', 'final', 'foundat', 'framework', 'function', 'fundament', 'good', 'graph', 'graph', 'hadoop', 'handson', 'homework', 'homework', 'import', 'inform', 'inform', 'infrastructur', 'inspir', 'internet', 'internet', 'java', 'key', 'keyword', 'knowledg', 'lab', 'lab', 'lab', 'laboratori', 'largescal', 'largescal', 'largescal', 'learn', 'learn', 'lectur', 'lectur', 'linear', 'linear', 'machin', 'machin', 'main', 'mapreduc', 'markov', 'materi', 'materi', 'media', 'midterm', 'mine', 'mine', 'mine', 'model', 'model', 'model', 'model', 'model', 'model', 'network', 'network', 'network', 'network', 'number', 'number', 'onlin', 'onlin', 'onlin', 'onlin', 'onlin', 'past', 'practic', 'practic', 'prerequisit', 'problem', 'problem', 'project', 'provid', 'question', 'real', 'realworld', 'realworld', 'realworld', 'realworld', 'recommend', 'recommend', 'recommend', 'reduct', 'relat', 'requir', 'retriev', 'search', 'selfcontain', 'servic', 'servic', 'servic', 'servic', 'servic', 'session', 'session', 'social', 'social', 'social', 'social', 'social', 'spark', 'specif', 'start', 'statist', 'stochast', 'stream', 'stream', 'structur', 'teach', 'techniqu', 'theoret', 'theori', 'topic', 'typic', 'ubiquit', 'user', 'weekli', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "# Print the terms in the pre-processed description of the IX class in alphabetical order\n",
    "\n",
    "for course in courses:\n",
    "\tif course['courseId'] == 'COM-308':\n",
    "\t\tdescription = course['description'].split()\n",
    "\t\tprint(sorted(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the mapping between terms and their indices, and documents and their indices\n",
    "\n",
    "terms = []\n",
    "for course in courses:\n",
    "  for word in course['description'].split():\n",
    "    terms.append(word)\n",
    "terms_indices = list(set(terms))\n",
    "\n",
    "document_indices = [x['courseId'] for x in courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5262, 854)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct matrix X\n",
    "\n",
    "M = len(terms_indices)\n",
    "N = len(document_indices)\n",
    "\n",
    "X = np.zeros((M, N))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate matrix X\n",
    "\n",
    "for i, word in enumerate(terms_indices):\n",
    "  for j, course in enumerate(courses):\n",
    "    description_list = course['description'].split()\n",
    "    freq = description_list.count(word)\n",
    "    X[i][j] = freq / len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96574156],\n",
       "       [0.98787981],\n",
       "       [3.45409433],\n",
       "       ...,\n",
       "       [5.65131891],\n",
       "       [6.74993119],\n",
       "       [6.05678401]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct IDF\n",
    "\n",
    "idf = np.zeros(len(terms_indices))\n",
    "\n",
    "for row in range(len(terms_indices)):\n",
    "\tfreq = 0\n",
    "\tfor val in X[row]:\n",
    "\t\tif val > 0:\n",
    "\t\t\tfreq += 1\n",
    "\tidf[row] = np.log(len(courses) / freq)\n",
    "\n",
    "idf = idf.reshape(len(idf), 1)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5262, 854)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct TF-IDF matrix\n",
    "\n",
    "tf_idf = X * idf\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('servic', 0.09381766001103216),\n",
       " ('realworld', 0.08748768295385784),\n",
       " ('onlin', 0.08673424009748963),\n",
       " ('social', 0.08119005782903743),\n",
       " ('explor', 0.07435342543791054),\n",
       " ('mine', 0.07185368695551898),\n",
       " ('largescal', 0.06218278450286707),\n",
       " ('ecommerc', 0.06212086167413974),\n",
       " ('auction', 0.05501165982224287),\n",
       " ('internet', 0.04927201071521289),\n",
       " ('network', 0.04732881922663084),\n",
       " ('ad', 0.04463626585630974),\n",
       " ('stream', 0.04292289062899521),\n",
       " ('dataset', 0.04292289062899521),\n",
       " ('data', 0.041592876685255915)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 15 terms in the description of the IX class with the highest TF-IDF scores.\n",
    "\n",
    "ix_idx = document_indices.index('COM-308')\n",
    "\n",
    "ix_words = tf_idf[:, ix_idx]\n",
    "ix_tf_idf_vals = {}\n",
    "for idx, val in enumerate(ix_words):\n",
    "\tif val < 0:\n",
    "\t\tcontinue\n",
    "\tix_tf_idf_vals[terms_indices[idx]] = val\n",
    "\n",
    "ix_tf_idf_vals_sorted = sorted(ix_tf_idf_vals.items(), key=lambda x:x[1], reverse = True)\n",
    "ix_tf_idf_vals_sorted[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('TFIDF_matrix.npy', tf_idf)\n",
    "np.save('document_indices.npy', document_indices)\n",
    "np.save('terms_indices.npy', terms_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix (first 5 rows):\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01555716 0.01924441 0.         ... 0.         0.03528142 0.03704549]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Document Indices (first 5):\n",
      "['MSE-440', 'BIO-695', 'FIN-523', 'MICRO-614', 'ME-231(a)']\n",
      "Terms Indices (first 5):\n",
      "['approxim', 'analysi', 'divers', 'matanya', 'refriger']\n"
     ]
    }
   ],
   "source": [
    "# Load the TF-IDF matrix\n",
    "tf_idf = np.load('TFIDF_matrix.npy')\n",
    "print(\"TF-IDF matrix (first 5 rows):\")\n",
    "print(tf_idf[:5])\n",
    "\n",
    "# Load the document indices\n",
    "document_indices = np.load('document_indices.npy', allow_pickle=True).tolist()\n",
    "print(\"Document Indices (first 5):\")\n",
    "print(document_indices[:5])\n",
    "\n",
    "# Load the terms indices\n",
    "terms_indices = np.load('terms_indices.npy', allow_pickle=True).tolist()\n",
    "print(\"Terms Indices (first 5):\")\n",
    "print(terms_indices[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain where the difference between the large scores and the small ones comes from.\n",
    "\n",
    "Words like 'onlin' and 'realworld' have higher scores as compared to terms like 'stream' and 'data'. This could be due to 'stream' and 'data' being frequently mentioned in other course descriptions as well. The difference in TF-IDF scores is influenced by how often these terms appear across all descriptions. Terms that are exclusive to that course will have a higher score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize markov and facebook matrices\n",
    "\n",
    "markov_chain = np.zeros(len(terms_indices))\n",
    "markov_chain[terms_indices.index('markov')] = 0.5\n",
    "markov_chain[terms_indices.index('chain')] = 0.5\n",
    "\n",
    "facebook = np.zeros(len(terms_indices))\n",
    "facebook[terms_indices.index('facebook')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare two documents\n",
    "\n",
    "def cosine_similarity(doc1, doc2):\n",
    "\tnorm_doc1 = np.linalg.norm(doc1)\n",
    "\tnorm_doc2 = np.linalg.norm(doc2)\n",
    "\treturn np.dot(doc1, doc2) / (norm_doc1 * norm_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for \"markov chains\"\n",
    "\n",
    "markov_similarity = []\n",
    "for idx in range(len(document_indices)):\n",
    "  markov_similarity.append(cosine_similarity(tf_idf.T[idx], markov_chain))\n",
    "\n",
    "# Dictionary {course name: similarity value}\n",
    "markov_sim_vals = {}\n",
    "for idx, sim in enumerate(markov_similarity):\n",
    "  markov_sim_vals[courses[idx]['name']] = sim\n",
    "\n",
    "# Sort by similarity value\n",
    "markov_sim_vals_sorted = sorted(markov_sim_vals.items(), key=lambda x:x[1], reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for \"facebook\"\n",
    "\n",
    "facebook_similarity = []\n",
    "for idx in range(len(document_indices)):\n",
    "    facebook_similarity.append(cosine_similarity(tf_idf.T[idx], facebook))\n",
    "\n",
    "# Dictionary {course name: similarity value}\n",
    "facebook_sim_vals = {}\n",
    "for idx, sim in enumerate(facebook_similarity):\n",
    "    facebook_sim_vals[courses[idx]['name']] = sim\n",
    "\n",
    "# Sort by similarity value\n",
    "facebook_sim_vals_sorted = sorted(facebook_sim_vals.items(), key=lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "markov chain - top five courses with similarity score\n",
      "('Applied stochastic processes', 0.557910816140559)\n",
      "('Applied probability & stochastic processes', 0.541839456832587)\n",
      "('Markov chains and algorithmic applications', 0.4210724606519117)\n",
      "('Supply chain management', 0.39279034730463636)\n",
      "('Mathematical models in supply chain management', 0.3076572352007134)\n",
      "\n",
      "facebook - top five courses with similarity score\n",
      "('Computational Social Media', 0.18922283654097266)\n",
      "('Composites technology', 0.0)\n",
      "('Image Processing for Life Science', 0.0)\n",
      "('Global business environment', 0.0)\n",
      "('Electrochemical nano-bio-sensing and bio/CMOS interfaces', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Display the top five courses together with their similarity score for each query.\n",
    "\n",
    "print(\"markov chain - top five courses with similarity score\")\n",
    "for i in range(5):\n",
    "    print(markov_sim_vals_sorted[i])\n",
    "\n",
    "print(\"\\nfacebook - top five courses with similarity score\")\n",
    "for i in range(5):\n",
    "    print(facebook_sim_vals_sorted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you think of the results? Give your intuition on what is happening.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of occurrences for\n",
      "markov: 45\n",
      "chain: 74\n",
      "facebook: 3\n"
     ]
    }
   ],
   "source": [
    "count_markov = 0\n",
    "count_chain = 0\n",
    "count_facebook = 0\n",
    "\n",
    "for course in courses:\n",
    "\tfor word in course['description'].split():\n",
    "\t\tif word == 'markov':\n",
    "\t\t\tcount_markov += 1\n",
    "\t\tif word == 'chain':\n",
    "\t\t\tcount_chain += 1\n",
    "\t\tif word == 'facebook':\n",
    "\t\t\tcount_facebook += 1\n",
    "\n",
    "print(\"Total number of occurrences for\")\n",
    "print(\"markov:\", count_markov)\n",
    "print(\"chain:\", count_chain)\n",
    "print(\"facebook:\", count_facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For markov chain, the top five courses with the highest similarity values all seem to be related to markov chain. However, for facebook, most of the similarity values of top five courses are 0. This suggests that this model is unable to detect courses that are related to facebook.\n",
    "\n",
    "Since facebook doesn't occur often in the descriptions, the TF-IDF model is unable to find similar courses for facebook. The TF-IDF model is only able to find similar courses for words that have a high number of occurrences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
